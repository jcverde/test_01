{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xuh1q23PRQ3","executionInfo":{"status":"ok","timestamp":1720039273104,"user_tz":-120,"elapsed":2110,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}},"outputId":"d7b5d4f3-c587-4635-ebbb-ea202a515be2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"SMnwDv4VM_E-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720039287284,"user_tz":-120,"elapsed":14183,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}},"outputId":"f2191ec8-a72d-4ce9-f975-7728b927c316"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.4)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.7.1)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]}],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dataclasses import dataclass\n","\n","!pip install wandb\n","import wandb\n","\n","import numpy as np\n","from pathlib import Path\n","\n","\n","torch.backends.cuda.matmul.allow_tf32 = False\n","torch.backends.cudnn.allow_tf32 = False"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-k1kGYAbM_FA","outputId":"616e1a33-e845-40b9-d9d6-8aa3724dd9f8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720039287724,"user_tz":-120,"elapsed":444,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Done!\n"]}],"source":["datapath = \"/content/drive/My Drive/datafiles/numerai/v4.1\"\n","filters = [('era', '=', \"0123\")]\n","df = pd.read_parquet(datapath + \"/era_123.parquet\", engine='pyarrow', filters=filters).dropna(axis=\"columns\")\n","\n","features = [f for f in df.columns if f.startswith(\"feature_\")]\n","targets  = [t for t in df.columns if t.startswith(\"target_\")]\n","num_features = len(features)\n","TARGET = \"target_nomi_v4_20\"\n","\n","print(\"Done!\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"bujOV6pNM_FB","executionInfo":{"status":"ok","timestamp":1720039287724,"user_tz":-120,"elapsed":8,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}}},"outputs":[],"source":["@dataclass\n","class ModelConfig:\n","    block_size: int = num_features            # num_features\n","    vocab_size: int = 5                       # 0..4\n","    n_layer: int = 6\n","    n_head: int = 8\n","    n_embed: int = 32\n","    dropout: float = 0.0\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.seq_embed = nn.Embedding(config.vocab_size, config.n_embed)\n","        self.pos_embed = nn.Embedding(config.block_size, config.n_embed)\n","        self.transformer = nn.TransformerEncoder(\n","            encoder_layer   = nn.TransformerEncoderLayer(\n","                                    d_model         = config.n_embed,\n","                                    nhead           = config.n_head ,\n","                                    dim_feedforward = config.n_embed * 4 ,\n","                                    dropout         = config.dropout ,\n","                                    activation      = \"relu\" ,\n","                                    batch_first     = True ,\n","                                    bias            = True      # Debería ser false, pero hay un bug en torch 2.2.2\n","                                ) ,\n","            num_layers      = config.n_layer\n","        )\n","        self.fc = nn.Linear(config.n_embed, config.vocab_size, bias=False)\n","\n","        n_params = sum(p.numel() for p in self.parameters())\n","        print(\"number of parameters: %.2fk\" % (n_params/1e3,))\n","\n","\n","    def forward(self, src, tgt=None):\n","        device = src.device\n","        b, t = src.size()          # (tamaño del batch, longitud de secuencia de src)\n","\n","        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0)   # shape (1, t)\n","\n","        src_embed = self.seq_embed(src)                 # shape (b, t, n_embed)\n","        pos_embed = self.pos_embed(pos)                 # shape (1, t, n_embed)\n","        x = self.transformer(src_embed + pos_embed)     # shape (b, t, n_embed)\n","        x = x[:, -1, :]                                 # shape (b, n_embed)\n","        logits = self.fc(x)                             # shape (b, vocab_size-1)\n","\n","        return logits"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4KVas8pNM_FC","outputId":"843f548b-8b05-4349-9dfc-27a5108b0b1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720039287725,"user_tz":-120,"elapsed":8,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["3128 783\n"]}],"source":["# Generar datos de train y test\n","split = int(len(df) * 0.8)\n","X_train = torch.from_numpy(df.loc[df.index[:split], features].to_numpy() * 4.0).to(torch.long)\n","X_test  = torch.from_numpy(df.loc[df.index[split:], features].to_numpy() * 4.0).to(torch.long)\n","y_train = torch.from_numpy(df.loc[df.index[:split], TARGET].to_numpy() * 4.0).to(torch.long)\n","y_test  = torch.from_numpy(df.loc[df.index[split:], TARGET].to_numpy() * 4.0).to(torch.long)\n","\n","num_rows_train = len(X_train)\n","num_rows_test  = len(X_test)\n","print(num_rows_train, num_rows_test)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"MCHOsKLhM_FC","outputId":"e5b118d4-bf17-4451-e0fa-6f1eee21b369","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720039289720,"user_tz":-120,"elapsed":2002,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["number of parameters: 123.46k\n","Device:  cuda\n"]}],"source":["filemodel = '/content/drive/My Drive/Colab Notebooks/numerai_era_01.model'\n","\n","device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","config      = ModelConfig()\n","model       = Transformer(config).to(device)\n","optimizer   = torch.optim.AdamW(model.parameters(), lr=1e-3)\n","\n","print(\"Device: \", device)\n","\n","\n","# Load model from disk\n","model_loaded_from_disk = False\n","if Path(filemodel+'--').is_file():\n","    print(\"Modelo cargado de disco\")\n","    model_loaded_from_disk = True\n","    saved_data = torch.load(filemodel, map_location=torch.device('cpu'))\n","    model.load_state_dict(saved_data['model_state_dict'])\n","    optimizer.load_state_dict(saved_data['optimizer_state_dict'])\n","    print(f\"Train loss: {saved_data['train_loss']:.3f}, Test loss: {saved_data['test_loss']:.3f}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"OCefynsAM_FC","outputId":"a97f1d26-9d8d-4e9b-99ea-65dd30bd7951","colab":{"base_uri":"https://localhost:8080/","height":212},"executionInfo":{"status":"ok","timestamp":1720039334424,"user_tz":-120,"elapsed":44709,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.17.4"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240703_204212-aqnekkun</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/jc-verde/numerai_era_00.py/runs/aqnekkun' target=\"_blank\">brisk-sea-10</a></strong> to <a href='https://wandb.ai/jc-verde/numerai_era_00.py' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/jc-verde/numerai_era_00.py' target=\"_blank\">https://wandb.ai/jc-verde/numerai_era_00.py</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/jc-verde/numerai_era_00.py/runs/aqnekkun' target=\"_blank\">https://wandb.ai/jc-verde/numerai_era_00.py/runs/aqnekkun</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jc-verde/numerai_era_00.py/runs/aqnekkun?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x79e085cd5780>"]},"metadata":{},"execution_count":7}],"source":["# Init WandB logging\n","wandb.init(\n","    project = \"numerai_era_00.py\",\n","    config = {\n","        \"num_features\":             config.block_size,\n","        \"era\":                      123,\n","        \"filemodel\":                filemodel,\n","        \"model_loaded_from_disk\":   model_loaded_from_disk,\n","        \"transformer/num_layers\":   config.n_layer,\n","        \"transformer/num_heads\":    config.n_head,\n","        \"transformer/dim\":          config.n_embed,\n","        \"transformer/dropout\":      config.dropout,\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9y8JVvgeM_FD","outputId":"c0957fdf-07fc-4d36-fd08-119118259d98","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch    0 - Train Loss: 1.484213 - Test Loss: 1.480178 [*]\n","Epoch    1 - Train Loss: 1.350970 - Test Loss: 1.342418 [*]\n","Epoch    2 - Train Loss: 1.312004 - Test Loss: 1.301006 [*]\n","Epoch    3 - Train Loss: 1.301045 - Test Loss: 1.288991 [*]\n","Epoch    4 - Train Loss: 1.299235 - Test Loss: 1.286936 [*]\n","Epoch    5 - Train Loss: 1.299493 - Test Loss: 1.287742\n","Epoch    6 - Train Loss: 1.299463 - Test Loss: 1.288876\n","Epoch    7 - Train Loss: 1.298968 - Test Loss: 1.289944\n","Epoch    8 - Train Loss: 1.298488 - Test Loss: 1.291223\n","Epoch    9 - Train Loss: 1.298375 - Test Loss: 1.292826\n","Epoch   10 - Train Loss: 1.298564 - Test Loss: 1.294527\n","Epoch   11 - Train Loss: 1.298661 - Test Loss: 1.295766\n","Epoch   12 - Train Loss: 1.298313 - Test Loss: 1.296129\n","Epoch   13 - Train Loss: 1.297470 - Test Loss: 1.295567\n","Epoch   14 - Train Loss: 1.296351 - Test Loss: 1.294362\n","Epoch   15 - Train Loss: 1.295261 - Test Loss: 1.292886\n","Epoch   16 - Train Loss: 1.294438 - Test Loss: 1.291454\n","Epoch   17 - Train Loss: 1.293944 - Test Loss: 1.290203\n","Epoch   18 - Train Loss: 1.293691 - Test Loss: 1.289117\n","Epoch   19 - Train Loss: 1.293529 - Test Loss: 1.288109\n","Epoch   20 - Train Loss: 1.293336 - Test Loss: 1.287117\n","Epoch   21 - Train Loss: 1.293083 - Test Loss: 1.286150 [*]\n","Epoch   22 - Train Loss: 1.292822 - Test Loss: 1.285279 [*]\n","Epoch   23 - Train Loss: 1.292638 - Test Loss: 1.284603 [*]\n","Epoch   24 - Train Loss: 1.292594 - Test Loss: 1.284178 [*]\n","Epoch   25 - Train Loss: 1.292690 - Test Loss: 1.283998 [*]\n","Epoch   26 - Train Loss: 1.292861 - Test Loss: 1.283991 [*]\n","Epoch   27 - Train Loss: 1.293008 - Test Loss: 1.284040\n","Epoch   28 - Train Loss: 1.293040 - Test Loss: 1.284036\n","Epoch   29 - Train Loss: 1.292923 - Test Loss: 1.283935 [*]\n","Epoch   30 - Train Loss: 1.292684 - Test Loss: 1.283765 [*]\n","Epoch   31 - Train Loss: 1.292394 - Test Loss: 1.283608 [*]\n","Epoch   32 - Train Loss: 1.292130 - Test Loss: 1.283533 [*]\n","Epoch   33 - Train Loss: 1.291935 - Test Loss: 1.283594\n","Epoch   34 - Train Loss: 1.291817 - Test Loss: 1.283792\n","Epoch   35 - Train Loss: 1.291750 - Test Loss: 1.284100\n","Epoch   36 - Train Loss: 1.291701 - Test Loss: 1.284472\n","Epoch   37 - Train Loss: 1.291647 - Test Loss: 1.284864\n","Epoch   38 - Train Loss: 1.291586 - Test Loss: 1.285245\n","Epoch   39 - Train Loss: 1.291528 - Test Loss: 1.285591\n","Epoch   40 - Train Loss: 1.291479 - Test Loss: 1.285874\n","Epoch   41 - Train Loss: 1.291437 - Test Loss: 1.286061\n","Epoch   42 - Train Loss: 1.291386 - Test Loss: 1.286117\n","Epoch   43 - Train Loss: 1.291306 - Test Loss: 1.286012\n","Epoch   44 - Train Loss: 1.291189 - Test Loss: 1.285746\n","Epoch   45 - Train Loss: 1.291043 - Test Loss: 1.285350\n","Epoch   46 - Train Loss: 1.290887 - Test Loss: 1.284875\n","Epoch   47 - Train Loss: 1.290740 - Test Loss: 1.284380\n","Epoch   48 - Train Loss: 1.290608 - Test Loss: 1.283914\n","Epoch   49 - Train Loss: 1.290485 - Test Loss: 1.283514 [*]\n","Epoch   50 - Train Loss: 1.290360 - Test Loss: 1.283195 [*]\n","Epoch   51 - Train Loss: 1.290224 - Test Loss: 1.282965 [*]\n","Epoch   52 - Train Loss: 1.290077 - Test Loss: 1.282817 [*]\n","Epoch   53 - Train Loss: 1.289922 - Test Loss: 1.282747 [*]\n","Epoch   54 - Train Loss: 1.289765 - Test Loss: 1.282735 [*]\n","Epoch   55 - Train Loss: 1.289605 - Test Loss: 1.282744\n","Epoch   56 - Train Loss: 1.289429 - Test Loss: 1.282732 [*]\n","Epoch   57 - Train Loss: 1.289227 - Test Loss: 1.282667 [*]\n","Epoch   58 - Train Loss: 1.288999 - Test Loss: 1.282540 [*]\n","Epoch   59 - Train Loss: 1.288752 - Test Loss: 1.282366 [*]\n","Epoch   60 - Train Loss: 1.288494 - Test Loss: 1.282171 [*]\n","Epoch   61 - Train Loss: 1.288232 - Test Loss: 1.281982 [*]\n","Epoch   62 - Train Loss: 1.287956 - Test Loss: 1.281815 [*]\n","Epoch   63 - Train Loss: 1.287655 - Test Loss: 1.281677 [*]\n","Epoch   64 - Train Loss: 1.287326 - Test Loss: 1.281557 [*]\n","Epoch   65 - Train Loss: 1.286975 - Test Loss: 1.281440 [*]\n","Epoch   66 - Train Loss: 1.286603 - Test Loss: 1.281293 [*]\n","Epoch   67 - Train Loss: 1.286203 - Test Loss: 1.281074 [*]\n","Epoch   68 - Train Loss: 1.285765 - Test Loss: 1.280754 [*]\n","Epoch   69 - Train Loss: 1.285287 - Test Loss: 1.280332 [*]\n","Epoch   70 - Train Loss: 1.284778 - Test Loss: 1.279845 [*]\n","Epoch   71 - Train Loss: 1.284242 - Test Loss: 1.279348 [*]\n","Epoch   72 - Train Loss: 1.283674 - Test Loss: 1.278882 [*]\n","Epoch   73 - Train Loss: 1.283080 - Test Loss: 1.278489 [*]\n","Epoch   74 - Train Loss: 1.282473 - Test Loss: 1.278197 [*]\n","Epoch   75 - Train Loss: 1.281854 - Test Loss: 1.277868 [*]\n","Epoch   76 - Train Loss: 1.281222 - Test Loss: 1.277500 [*]\n","Epoch   77 - Train Loss: 1.280594 - Test Loss: 1.277105 [*]\n","Epoch   78 - Train Loss: 1.279986 - Test Loss: 1.276713 [*]\n","Epoch   79 - Train Loss: 1.279421 - Test Loss: 1.276398 [*]\n","Epoch   80 - Train Loss: 1.278899 - Test Loss: 1.276227 [*]\n","Epoch   81 - Train Loss: 1.278431 - Test Loss: 1.276140 [*]\n","Epoch   82 - Train Loss: 1.278020 - Test Loss: 1.276012 [*]\n","Epoch   83 - Train Loss: 1.277653 - Test Loss: 1.275758 [*]\n","Epoch   84 - Train Loss: 1.277315 - Test Loss: 1.275423 [*]\n","Epoch   85 - Train Loss: 1.276985 - Test Loss: 1.275057 [*]\n","Epoch   86 - Train Loss: 1.276641 - Test Loss: 1.274643 [*]\n","Epoch   87 - Train Loss: 1.276271 - Test Loss: 1.274098 [*]\n","Epoch   88 - Train Loss: 1.275867 - Test Loss: 1.273380 [*]\n","Epoch   89 - Train Loss: 1.275434 - Test Loss: 1.272541 [*]\n","Epoch   90 - Train Loss: 1.274985 - Test Loss: 1.271644 [*]\n","Epoch   91 - Train Loss: 1.274532 - Test Loss: 1.270761 [*]\n","Epoch   92 - Train Loss: 1.274093 - Test Loss: 1.269902 [*]\n","Epoch   93 - Train Loss: 1.273681 - Test Loss: 1.269046 [*]\n","Epoch   94 - Train Loss: 1.273303 - Test Loss: 1.268224 [*]\n","Epoch   95 - Train Loss: 1.272961 - Test Loss: 1.267459 [*]\n","Epoch   96 - Train Loss: 1.272648 - Test Loss: 1.266754 [*]\n","Epoch   97 - Train Loss: 1.272365 - Test Loss: 1.266090 [*]\n","Epoch   98 - Train Loss: 1.272095 - Test Loss: 1.265454 [*]\n","Epoch   99 - Train Loss: 1.271838 - Test Loss: 1.264852 [*]\n","Epoch  100 - Train Loss: 1.271586 - Test Loss: 1.264306 [*]\n","Epoch  101 - Train Loss: 1.271329 - Test Loss: 1.263808 [*]\n","Epoch  102 - Train Loss: 1.271060 - Test Loss: 1.263335 [*]\n","Epoch  103 - Train Loss: 1.270780 - Test Loss: 1.262868 [*]\n","Epoch  104 - Train Loss: 1.270494 - Test Loss: 1.262447 [*]\n","Epoch  105 - Train Loss: 1.270201 - Test Loss: 1.262014 [*]\n","Epoch  106 - Train Loss: 1.269895 - Test Loss: 1.261569 [*]\n","Epoch  107 - Train Loss: 1.269582 - Test Loss: 1.261084 [*]\n","Epoch  108 - Train Loss: 1.269265 - Test Loss: 1.260623 [*]\n","Epoch  109 - Train Loss: 1.268945 - Test Loss: 1.260162 [*]\n","Epoch  110 - Train Loss: 1.268617 - Test Loss: 1.259659 [*]\n","Epoch  111 - Train Loss: 1.268283 - Test Loss: 1.259177 [*]\n","Epoch  112 - Train Loss: 1.267951 - Test Loss: 1.258755 [*]\n","Epoch  113 - Train Loss: 1.267629 - Test Loss: 1.258382 [*]\n","Epoch  114 - Train Loss: 1.267300 - Test Loss: 1.257965 [*]\n","Epoch  115 - Train Loss: 1.266979 - Test Loss: 1.257534 [*]\n","Epoch  116 - Train Loss: 1.266662 - Test Loss: 1.257210 [*]\n","Epoch  117 - Train Loss: 1.266356 - Test Loss: 1.256884 [*]\n","Epoch  118 - Train Loss: 1.266055 - Test Loss: 1.256495 [*]\n","Epoch  119 - Train Loss: 1.265758 - Test Loss: 1.256199 [*]\n","Epoch  120 - Train Loss: 1.265468 - Test Loss: 1.255976 [*]\n","Epoch  121 - Train Loss: 1.265179 - Test Loss: 1.255661 [*]\n","Epoch  122 - Train Loss: 1.264897 - Test Loss: 1.255348 [*]\n","Epoch  123 - Train Loss: 1.264618 - Test Loss: 1.255141 [*]\n","Epoch  124 - Train Loss: 1.264340 - Test Loss: 1.254758 [*]\n","Epoch  125 - Train Loss: 1.264077 - Test Loss: 1.254411 [*]\n","Epoch  126 - Train Loss: 1.263815 - Test Loss: 1.254148 [*]\n","Epoch  127 - Train Loss: 1.263553 - Test Loss: 1.253810 [*]\n","Epoch  128 - Train Loss: 1.263295 - Test Loss: 1.253653 [*]\n","Epoch  129 - Train Loss: 1.263049 - Test Loss: 1.253514 [*]\n","Epoch  130 - Train Loss: 1.262817 - Test Loss: 1.253414 [*]\n","Epoch  131 - Train Loss: 1.262584 - Test Loss: 1.253403 [*]\n","Epoch  132 - Train Loss: 1.262348 - Test Loss: 1.253397 [*]\n","Epoch  133 - Train Loss: 1.262119 - Test Loss: 1.253504\n","Epoch  134 - Train Loss: 1.261892 - Test Loss: 1.253561\n","Epoch  135 - Train Loss: 1.261668 - Test Loss: 1.253667\n","Epoch  136 - Train Loss: 1.261455 - Test Loss: 1.253768\n","Epoch  137 - Train Loss: 1.261237 - Test Loss: 1.253754\n","Epoch  138 - Train Loss: 1.261022 - Test Loss: 1.253791\n","Epoch  139 - Train Loss: 1.260900 - Test Loss: 1.253504\n","Epoch  140 - Train Loss: 1.261220 - Test Loss: 1.254698\n","Epoch  141 - Train Loss: 1.262703 - Test Loss: 1.255000\n","Epoch  142 - Train Loss: 1.261593 - Test Loss: 1.256041\n","Epoch  143 - Train Loss: 1.260034 - Test Loss: 1.253814\n","Epoch  144 - Train Loss: 1.260092 - Test Loss: 1.253880\n","Epoch  145 - Train Loss: 1.260606 - Test Loss: 1.255653\n","Epoch  146 - Train Loss: 1.259637 - Test Loss: 1.253905\n","Epoch  147 - Train Loss: 1.259172 - Test Loss: 1.254043\n","Epoch  148 - Train Loss: 1.259686 - Test Loss: 1.255779\n","Epoch  149 - Train Loss: 1.258972 - Test Loss: 1.254152\n","Epoch  150 - Train Loss: 1.258519 - Test Loss: 1.253897\n","Epoch  151 - Train Loss: 1.258895 - Test Loss: 1.255049\n","Epoch  152 - Train Loss: 1.258235 - Test Loss: 1.253406\n","Epoch  153 - Train Loss: 1.257844 - Test Loss: 1.253373 [*]\n"]}],"source":["batch_size = 512        # Optimizado para la instancia T4 de Colab\n","best_test_loss = 1e9\n","\n","for epoch in range(1000):\n","    model.train()\n","    optimizer.zero_grad(set_to_none=True)\n","    train_loss = []\n","\n","    for i in range((num_rows_train+1) // batch_size):\n","        ini = i * batch_size\n","        fin = min(num_rows_train, (i+1)*batch_size)\n","        X = X_train[ini:fin].to(device)\n","        y = y_train[ini:fin].to(device)\n","\n","        out = model(X)\n","        loss = F.cross_entropy(out, y)\n","        loss.backward()\n","        train_loss.append(loss.item())\n","\n","    if epoch % 1 == 0:\n","        with torch.no_grad():\n","            #model.eval()      # <--- por lo que sea, esto provoca errores extraños al ejecutar 'model(X)'\n","            test_loss = []\n","            for i in range((num_rows_test+1) // batch_size):\n","                ini = i * batch_size\n","                fin = min(num_rows_test, (i+1)*batch_size)\n","                X = X_test[ini:fin].to(device)\n","                y = y_test[ini:fin].to(device)\n","                out = model(X)\n","                test_loss.append(F.cross_entropy(out, y).item())\n","\n","            test_loss_mean = np.mean(test_loss)\n","            msg = f\"Epoch {epoch:4d} - Train Loss: {np.mean(train_loss):.6f} - Test Loss: {test_loss_mean:.6f}\"\n","            wandb.log({\"train_loss\": np.mean(train_loss), \"test_loss\": test_loss_mean})\n","\n","            if test_loss_mean < best_test_loss:\n","                best_test_loss = test_loss_mean\n","                torch.save({\n","                    'epoch'                 : epoch,\n","                    'model_state_dict'      : model.state_dict(),\n","                    'optimizer_state_dict'  : optimizer.state_dict(),\n","                    'train_loss'            : np.mean(train_loss),\n","                    'test_loss'             : test_loss_mean,\n","                    }, filemodel)    # Almacenar los weights porque son los mejores hasta el momento\n","                msg += \" [*]\"\n","\n","            print(msg)\n","\n","\n","    # Actualizar weights\n","    optimizer.step()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLugETVnM_FD","executionInfo":{"status":"aborted","timestamp":1720039411784,"user_tz":-120,"elapsed":5,"user":{"displayName":"Juan Carlos Verde","userId":"03627255909139193326"}}},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}